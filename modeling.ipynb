{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce1f7878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from processing_functions import create_numeric_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c497edb3",
   "metadata": {},
   "source": [
    "In this notebook I'm going to attempt to reproduce the findings in the dataset paper regarding the five benchmark models they tried: LightGBM (hyperparameter optimized by Hyperopt), Multilayer Perceptron (1 hidden layer of 3 neurons), Random Forests, Support Vector Machine (polynomial kernel) and kNearestNeighbor (k = 3). They considered both the AD-CN (Alzheimer's vs. Healthy) and the FTD-CN (Frontotemporal Dementia vs. Healthy) classification problems. The metrics they reported were accuracy, sensitivity, specificity, and F1 score, obtained by Leave-One-Subject-Out cross-validation. This cross-validation method iterates through all subjects, iteratively leaves out one subject at a time, builds a model using the rest of the dataset, and then computes the confusion matrix for that model's predictions on the data corresponding to the left-out subject. These confusion matrices are then summed over the results corresponding to each subject being left out and the metrics are then computed from the resulting total confusion matrix. \n",
    "\n",
    "I will be using two different processing methods to obtain the relative band power and comparing the results. The first method is the one indicated in the dataset paper, which takes epoch_length = 2000 (4 seconds) and nperseg = 256 (default value, frequency resolution ~ 1.95). The other method is one I found that suggested in a sleep research blog post that also partially conforms with the method used in the CNN paper, which is to take epoch_length = 15000 (30 seconds) and nperseg = 2000 (frequency resolution 0.25).  I'll be referring to the first as \"short epochs\" and the second as \"long epochs\". The short epochs method has the advantage of producing a much larger dataset to train on but has the disadvantage that the frequency resolution is far too low to accurately capture the lower cutoff of the Delta range or even the cutoff between the Alpha and Beta ranges. The long epochs method produces a much smaller dataset but has the advantage of allowing precise integration over each of the five frequency bands. \n",
    "\n",
    "To obtain the .npy files used in this notebook you should run the following code block uncommented at the end of the data_processing notebook (after running the imports and the function definition blocks). You can of course also experiment with other choices of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4f058f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nprocess_and_save(epoch_length=2000,overlap_ratio=0.5,freq_bands=np.array([0.5,4.0,8.0,13.0,25.0,45.0]),nperseg=256,filenames=['short_num_epochs','short_rbp'])\\nprocess_and_save(epoch_length=15000,overlap_ratio=0.5,freq_bands=np.array([0.5,4.0,8.0,13.0,25.0,45.0]),nperseg=2000,filenames=['long_num_epochs','long_rbp'])\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "process_and_save(epoch_length=2000,overlap_ratio=0.5,freq_bands=np.array([0.5,4.0,8.0,13.0,25.0,45.0]),nperseg=256,filenames=['processed_data/short_num_epochs','processed_data/short_rbp'])\n",
    "process_and_save(epoch_length=15000,overlap_ratio=0.5,freq_bands=np.array([0.5,4.0,8.0,13.0,25.0,45.0]),nperseg=2000,filenames=['processed_data/short_num_epochs','processed_data/short_rbp'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913b099e",
   "metadata": {},
   "source": [
    "If everything goes well then the following code block should execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b60c1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_num_epochs = np.load('processed_data/short_num_epochs.npy')\n",
    "long_num_epochs = np.load('processed_data/long_num_epochs.npy')\n",
    "short_rbp = np.load('processed_data/short_rbp.npy')\n",
    "long_rbp = np.load('processed_data/long_rbp.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6721eea6",
   "metadata": {},
   "source": [
    "The shapes should be (88,), (88,), (88,639,5,19), (88,84,5,19)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a29ea6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88,)\n",
      "(88,)\n",
      "(88, 639, 5, 19)\n",
      "(88, 84, 5, 19)\n"
     ]
    }
   ],
   "source": [
    "print(short_num_epochs.shape)\n",
    "print(long_num_epochs.shape)\n",
    "print(short_rbp.shape)\n",
    "print(long_rbp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c31269",
   "metadata": {},
   "source": [
    "The following piece of code creates numerical labels for the target variable: 0 for healthy group, 1 for Alzheimer's, and 2 for Frontotemporal dementia. The subject indices for the resulting array are aligned with the subject indices (the first dimension) for each of the arrays we loaded in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b51b45a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppt_diagnostics = pd.read_csv('data/ds004504/participants.tsv',sep='\\t')\n",
    "target_labels = ppt_diagnostics['Group'].apply(create_numeric_labels).values\n",
    "target_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bc078f",
   "metadata": {},
   "source": [
    "The sklearn models expect the input to take the form (number of examples) x (number of features). This requires flattening some of the dimensions of our arrays, which is done using the following helper function. The partial_flatten function reshapes the relative band power array so that the first dimension is epochs and the second dimension covers the relative band power for each of the five bands across all 19 channels. The num_epochs array we loaded in is passed as the second argument in order to easily exclude the zero-padded parts of the array. The function also returns a 1-d array of dimension (number of examples,) containing the corresponding class labels for each of these epochs. \n",
    "\n",
    "The function assumes that classes that aren't used in the classification have already been removed from the rbp_array, i.e., if you are doing Alzheimer's/healthy classification (for instance) then all FTD examples have been removed. This can be done by feeding the rbp_array, num_epochs, and target_labels into the remove_class function first and then feeding the results into the partial_flatten function. \n",
    "\n",
    "If the \"exclude\" argument is not None then the subject corresponding to that index is left out in the returned arrays. Note that this exclude index corresponds to the index of the subject in the rbp_array being fed into the function, which may not necessarily be the same as the subject's index in the original rbp array that we loaded. The flatten_final argument is a boolean that specifies whether or not the bands x channels part of the array should be flattened into a single dimension. This defaults to True, which is used for the sklearn models, but the non-flattened version will likely later be used in some other models (it's used in the CNN paper, for instance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "231f24fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_class(rbp_array,num_epochs,target_labels,class_):\n",
    "    if class_ == 'F':\n",
    "        return rbp_array[:65].copy(),num_epochs[:65].copy(),target_labels[:65].copy()\n",
    "    if class_ == 'A':\n",
    "        return rbp_array[36:].copy(),num_epochs[36:].copy(),target_labels[36:].copy()\n",
    "    if class_ == 'C':\n",
    "        return np.concatenate(rbp_array[:36],rbp_array[65:]), np.concatenate(num_epochs[:36],num_epochs[65:]), np.concatenate(target_labels[:36],target_labels[65:])\n",
    "\n",
    "def partial_flatten(rbp_array,num_epochs,target_labels,exclude=None,flatten_final=True):\n",
    "    total_subjects = len(target_labels)\n",
    "    feature_arrays = []\n",
    "    target_arrays = []\n",
    "    for i in range(total_subjects):\n",
    "        feature_arrays.append(rbp_array[i,0:num_epochs[i],:,:])\n",
    "        target_arrays.append(target_labels[i]*np.ones(num_epochs[i]))\n",
    "    if exclude==None: \n",
    "        features= np.concatenate(feature_arrays)\n",
    "        targets = np.concatenate(target_arrays)\n",
    "    else:\n",
    "        features= np.concatenate(feature_arrays[:exclude] + feature_arrays[exclude+1:])\n",
    "        targets = np.concatenate(target_arrays[:exclude] + target_arrays[exclude+1:])\n",
    "    if flatten_final:\n",
    "        features = features.reshape((features.shape[0],-1))\n",
    "    return features, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d417d2",
   "metadata": {},
   "source": [
    "The next set of functions take in a 2 x 2 (total) confusion matrix presented as a numpy array and compute the metrics we are interested in. These functions assume that the 0-index of the confusion matrix corresponds to negative examples and the 1-index corresponds to positive examples. \n",
    "\n",
    "In the comments TP = True Positive, TN = True Negative, FP = False Positive, FN = False Negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c985d109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(confusion):\n",
    "    # (TN + TP)/total\n",
    "    return (confusion[0,0]+confusion[1,1])/np.sum(confusion)\n",
    "def sensitivity(confusion):\n",
    "    # TP/(TP+FN)\n",
    "    return confusion[1,1]/(confusion[1,1]+confusion[1,0])\n",
    "def specificity(confusion):\n",
    "    # TN/(TN+FP)\n",
    "    return confusion[0,0]/(confusion[0,0]+confusion[0,1])\n",
    "def precision(confusion):\n",
    "    # TP/(TP+FP)\n",
    "    return confusion[1,1]/(confusion[1,1]+confusion[0,1])\n",
    "def f1(confusion):\n",
    "    # harmonic mean of precision and sensitivity\n",
    "    return 2*(precision(confusion)*sensitivity(confusion))/(precision(confusion)+sensitivity(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d3f19c",
   "metadata": {},
   "source": [
    "The function below runs our two-class kNN modeling routine with leave-one-subject-out cross-validation. It returns a dictionary of cross-validation accuracy, sensitivity, specificity, and F1 scores computed from the total confusion matrix. removed_class indicates the class to be excluded to create a two-class classification problem (same labels as the remove_class function) and n_neighbors indicates the number of neighbors k to use in kNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1f4ec6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN_cross(rbp_array,num_epochs,target_labels,removed_class,n_neighbors):\n",
    "    if removed_class == 'F':\n",
    "        labels = [0,1]\n",
    "    if removed_class == 'A':\n",
    "        labels = [0,2]\n",
    "    if removed_class == 'C':\n",
    "        labels = [1,2]\n",
    "    confusion_matrices = []\n",
    "    mod_rbp, mod_num_epochs, mod_target_labels = remove_class(rbp_array,num_epochs,target_labels,removed_class)\n",
    "    for i in range(len(mod_target_labels)):\n",
    "        train_X, train_y = partial_flatten(mod_rbp,mod_num_epochs,mod_target_labels,exclude=i,flatten_final=True)\n",
    "        test_X = mod_rbp[i,0:mod_num_epochs[i],:,:].reshape(mod_num_epochs[i],-1)\n",
    "        test_y = mod_target_labels[i]*np.ones(mod_num_epochs[i])\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        train_X = scaler.fit_transform(train_X)\n",
    "        \n",
    "        ThreeNN = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "        ThreeNN.fit(train_X, train_y)\n",
    "        \n",
    "        test_X = scaler.transform(test_X)\n",
    "        \n",
    "        confusion_matrices += [confusion_matrix(test_y,ThreeNN.predict(test_X),labels=labels)]\n",
    "    confusion_matrices = np.array(confusion_matrices)\n",
    "    total_confusion = np.sum(confusion_matrices, axis= 0)\n",
    "    return {'acc':accuracy(total_confusion), 'sens':sensitivity(total_confusion), 'spec':specificity(total_confusion), 'f1':f1(total_confusion)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405f7733",
   "metadata": {},
   "source": [
    "Below we do leave-one-subject-out cross-validation for a two class kNN classifier for Alzheimer's vs Healthy with k = 3. Both the short and long epoch versions are done. \n",
    "\n",
    "First the short version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b05b3eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.6473271507200482,\n",
       " 'sens': 0.638900372054568,\n",
       " 'spec': 0.6575091575091575,\n",
       " 'f1': 0.6647073581592058}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_ThreeNN_metrics = kNN_cross(short_rbp,short_num_epochs,target_labels,removed_class='F',n_neighbors=3)\n",
    "short_ThreeNN_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a502c2fd",
   "metadata": {},
   "source": [
    "Now the long version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "31271d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.6884960880904086,\n",
       " 'sens': 0.6636652542372882,\n",
       " 'spec': 0.7184900831733845,\n",
       " 'f1': 0.6998045238760123}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_ThreeNN_metrics = kNN_cross(long_rbp,long_num_epochs,target_labels,removed_class='F',n_neighbors=3)\n",
    "long_ThreeNN_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df92e7c",
   "metadata": {},
   "source": [
    "Note the significant boost in performance (3-4% across all 4 metrics). They are still each about 2% worse than the paper's reported perforamnce of kNN on these metrics with the short epoch version. Still not sure why that's the case. \n",
    "\n",
    "Below we also look at the performance of the classifier for healthy vs. FTD for the short epoch version and long epoch version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2e5b5280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.6413633224819967,\n",
       " 'sens': 0.5192447349310094,\n",
       " 'spec': 0.7253579753579753,\n",
       " 'f1': 0.5412907702984039}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_ThreeNN_metrics = kNN_cross(short_rbp,short_num_epochs,target_labels,removed_class='A',n_neighbors=3)\n",
    "short_ThreeNN_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5ed010d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.7318647930117737,\n",
       " 'sens': 0.6177570093457944,\n",
       " 'spec': 0.8099808061420346,\n",
       " 'f1': 0.6518737672583826}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_ThreeNN_metrics = kNN_cross(long_rbp,long_num_epochs,target_labels,removed_class='A',n_neighbors=3)\n",
    "long_ThreeNN_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69e6463",
   "metadata": {},
   "source": [
    "The long epoch version has quite good accuracy and specificity for FTD vs. healthy (with the short version not being terrible either), though we can see that this comes at the cost of worse sensititivy and worse F1 scores. The low sensitivity and high specificity for both the short and long version in particular means that the classifier is not great at identifying FTD cases as being FTD. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
